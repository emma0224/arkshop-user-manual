# CLIP

CLIP(Contrastive Language-Image Pre-Training) 模型是 OpenAI 在 2021 年初发布的用于匹配图像和文本的预训练神经网络模型，是近年来在多模态研究领域的经典之作。该模型直接使用大量的互联网数据进行预训练，在很多任务表现上达到了目前最佳表现（SOTA） 。

参考：[https://github.com/openai/CLIP](https://github.com/openai/CLIP)
